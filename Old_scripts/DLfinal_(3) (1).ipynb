{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHp7SysJf-f",
        "outputId": "f947f856-82de-4f56-9170-d95c5208da73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/isic16\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sarlren/isic16\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IysWIYJdLvzA",
        "outputId": "7f1d6878-3e18-4321-d441-4697a4a24fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedSegDiff'...\n",
            "remote: Enumerating objects: 716, done.\u001b[K\n",
            "remote: Counting objects: 100% (397/397), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 716 (delta 340), reused 248 (delta 248), pack-reused 319 (from 2)\u001b[K\n",
            "Receiving objects: 100% (716/716), 3.90 MiB | 12.08 MiB/s, done.\n",
            "Resolving deltas: 100% (396/396), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WuJunde/MedSegDiff.git\n",
        "!mv MedSegDiff/* ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExdmMQJmKbpQ",
        "outputId": "303ce32a-f243-464f-9764-2629cef701d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kqDGAVprODFj"
      },
      "outputs": [],
      "source": [
        "!mkdir /kaggle/working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wPgkhLO1ODi0"
      },
      "outputs": [],
      "source": [
        "!mkdir /kaggle/working/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fj_l69maOFoc"
      },
      "outputs": [],
      "source": [
        "!mkdir /kaggle/working/isic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mmB8pgj5cwBe"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/guided_diffusion /content/scripts/guided_diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2Qy0qHqODrL"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "subprocess.call(\"cp -r \"+path+\"/ISBI2016_ISIC_Part1_Test_Data/* /kaggle/working/isic/\", shell=True)\n",
        "subprocess.call(\"cp -r \"+path+\"/ISBI2016_ISIC_Part1_Training_Data/* /kaggle/working/isic/\", shell=True)\n",
        "subprocess.call(\"cp -r \"+path+\"/ISBI2016_ISIC_Part1_Training_GroundTruth/* /kaggle/working/isic/\", shell=True)\n",
        "subprocess.call(\"cp -r \"+path+\"/ISBI2016_ISIC_Part1_Test_GroundTruth/* /kaggle/working/isic/\", shell=True)\n",
        "subprocess.call(\"cp \"+path+\"/ISBI2016_ISIC_Part3B_Test_GroundTruth.csv /kaggle/working/isic/\", shell=True)\n",
        "subprocess.call(\"cp \"+path+\"/ISBI2016_ISIC_Part3B_Training_GroundTruth.csv /kaggle/working/isic/\", shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "X3KfrcTjJ8VL"
      },
      "outputs": [],
      "source": [
        "!pip install blobfile\n",
        "!pip install nibabel\n",
        "!pip install visdom\n",
        "!pip install torchsummary\n",
        "!pip install batchgenerators\n",
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb"
      ],
      "metadata": {
        "id": "eep4KKwVuOyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z6pr6GhgFOG"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(\"/content/scripts\")\n",
        "sys.path.append(\"./\")\n",
        "from ssl import OP_NO_TLSv1\n",
        "import nibabel as nib\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "import torch.distributed as dist\n",
        "import torchvision.utils as vutils\n",
        "from guided_diffusion import dist_util, logger\n",
        "from guided_diffusion.resample import create_named_schedule_sampler\n",
        "from guided_diffusion.bratsloader import BRATSDataset, BRATSDataset3D\n",
        "from guided_diffusion.isicloader import ISICDataset\n",
        "from guided_diffusion.custom_dataset_loader import CustomDataset\n",
        "from guided_diffusion.script_util import (\n",
        "    NUM_CLASSES,\n",
        "    model_and_diffusion_defaults,\n",
        "    create_model_and_diffusion,\n",
        "    args_to_dict,\n",
        "    add_dict_to_argparser,\n",
        ")\n",
        "import torch as th\n",
        "from guided_diffusion.train_util import TrainLoop\n",
        "from guided_diffusion.utils import staple\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Args:\n",
        "  data_name: str\n",
        "  data_dir: str\n",
        "  out_dir: str\n",
        "  image_size: int\n",
        "  num_channels: int\n",
        "  class_cond: bool\n",
        "  num_res_blocks: int\n",
        "  num_heads: int\n",
        "  learn_sigma: bool\n",
        "  use_scale_shift_norm: bool\n",
        "  attention_resolutions: str\n",
        "  diffusion_steps: int\n",
        "  noise_schedule: str\n",
        "  rescale_learned_sigmas: bool\n",
        "  rescale_timesteps: bool\n",
        "  lr: float\n",
        "  batch_size: int\n",
        "  patience: int\n",
        "  min_delta: float\n",
        "  microbatch: int\n",
        "  ema_rate: str\n",
        "  log_interval: int\n",
        "  save_interval: int\n",
        "  resume_checkpoint: str\n",
        "  schedule_sampler: str\n",
        "  weight_decay: float\n",
        "  lr_anneal_steps: int\n",
        "  use_fp16: bool\n",
        "  fp16_scale_growth: float\n",
        "  gpu_dev: str\n",
        "  multi_gpu: str\n",
        "  in_ch: int\n",
        "  num_heads_upsample: int\n",
        "  num_head_channels: int\n",
        "  resblock_updown: bool\n",
        "  dpm_solver: bool\n",
        "  version: str\n",
        "  channel_mult: str\n",
        "  dropout: float\n",
        "  use_checkpoint: bool\n",
        "  use_new_attention_order: bool\n",
        "  timestep_respacing: str\n",
        "  use_kl: bool\n",
        "  predict_xstart: bool\n",
        "  model_path: str\n",
        "  num_ensemble: int\n",
        "  use_ddim: bool\n",
        "  clip_denoised: bool\n",
        "\n",
        "argsdict = dict(\n",
        "  data_name = 'ISIC',\n",
        "  data_dir = \"/kaggle/working/isic\",\n",
        "  out_dir = \"/kaggle/working/out\",\n",
        "  image_size = 256,\n",
        "  num_channels = 128,\n",
        "  class_cond = False,\n",
        "  num_res_blocks = 2,\n",
        "  num_heads = 1,\n",
        "  learn_sigma = True,\n",
        "  use_scale_shift_norm = False,\n",
        "  attention_resolutions = \"16\",\n",
        "  diffusion_steps = 1000,\n",
        "  noise_schedule = 'linear',\n",
        "  rescale_learned_sigmas = False,\n",
        "  rescale_timesteps = False,\n",
        "  lr = 1e-4,\n",
        "  batch_size = 4,\n",
        "  patience = 2,\n",
        "  min_delta = 0.001,\n",
        "  microbatch = -1,  # -1 disables microbatches\n",
        "  ema_rate = \"0.9999\",  # comma-separated list of EMA values\n",
        "  log_interval = 100,\n",
        "  save_interval = 5000,\n",
        "  resume_checkpoint = None, #\"/results/pretrainedmodel.pt\"\n",
        "  schedule_sampler=\"uniform\",\n",
        "  weight_decay=0.0,\n",
        "  lr_anneal_steps=400, # used for early stopping\n",
        "  use_fp16=False,\n",
        "  fp16_scale_growth=1e-3,\n",
        "  gpu_dev = \"0\",\n",
        "  multi_gpu = None, #\"0,1,2\"\n",
        "\n",
        "  # useful for sampling only:\n",
        "  model_path = \"/kaggle/working/out/savedmodel000400.pt\",\n",
        "  num_ensemble = 5,\n",
        "  use_ddim = False, #originally False\n",
        "  clip_denoised = True,\n",
        ")\n",
        "argsdict.update(model_and_diffusion_defaults())\n",
        "\n",
        "args = Args(**argsdict)\n",
        "\n",
        "seed=10\n",
        "th.manual_seed(seed)\n",
        "th.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    dist_util.setup_dist(args)\n",
        "    logger.configure(dir = args.out_dir)\n",
        "\n",
        "    logger.log(\"creating data loader...\")\n",
        "\n",
        "    if args.data_name == 'ISIC':\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)), transforms.ToTensor(),]\n",
        "        transform_train = transforms.Compose(tran_list)\n",
        "\n",
        "        ds = ISICDataset(args, args.data_dir, transform_train)\n",
        "        args.in_ch = 4\n",
        "    elif args.data_name == 'BRATS':\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)),]\n",
        "        transform_train = transforms.Compose(tran_list)\n",
        "\n",
        "        ds = BRATSDataset3D(args.data_dir, transform_train, test_flag=False)\n",
        "        args.in_ch = 5\n",
        "    else :\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)), transforms.ToTensor(),]\n",
        "        transform_train = transforms.Compose(tran_list)\n",
        "        print(\"Your current directory : \",args.data_dir)\n",
        "        ds = CustomDataset(args, args.data_dir, transform_train)\n",
        "        args.in_ch = 4\n",
        "\n",
        "    datal= th.utils.data.DataLoader(\n",
        "        ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True)\n",
        "    data = iter(datal)\n",
        "\n",
        "    logger.log(\"creating model and diffusion...\")\n",
        "\n",
        "    model, diffusion = create_model_and_diffusion(\n",
        "        **args_to_dict(args, model_and_diffusion_defaults().keys())\n",
        "    )\n",
        "    if args.multi_gpu:\n",
        "        model = th.nn.DataParallel(model,device_ids=[int(id) for id in args.multi_gpu.split(',')])\n",
        "        model.to(device = th.device('cuda', int(args.gpu_dev)))\n",
        "    else:\n",
        "        model.to(dist_util.dev())\n",
        "    schedule_sampler = create_named_schedule_sampler(args.schedule_sampler, diffusion,  maxt=args.diffusion_steps)\n",
        "\n",
        "\n",
        "    logger.log(\"training...\")\n",
        "    TrainLoop(\n",
        "        model=model,\n",
        "        diffusion=diffusion,\n",
        "        classifier=None,\n",
        "        data=data,\n",
        "        dataloader=datal,\n",
        "        batch_size=args.batch_size,\n",
        "        microbatch=args.microbatch,\n",
        "        lr=args.lr,\n",
        "        ema_rate=args.ema_rate,\n",
        "        log_interval=args.log_interval,\n",
        "        save_interval=args.save_interval,\n",
        "        resume_checkpoint=args.resume_checkpoint,\n",
        "        use_fp16=args.use_fp16,\n",
        "        fp16_scale_growth=args.fp16_scale_growth,\n",
        "        schedule_sampler=schedule_sampler,\n",
        "        weight_decay=args.weight_decay,\n",
        "        lr_anneal_steps=args.lr_anneal_steps,\n",
        "    ).run_loop()\n",
        "\n",
        "def visualize(img):\n",
        "    _min = img.min()\n",
        "    _max = img.max()\n",
        "    normalized_img = (img - _min)/ (_max - _min)\n",
        "    return normalized_img\n",
        "\n",
        "\n",
        "def sample():\n",
        "    dist_util.setup_dist(args)\n",
        "    logger.configure(dir = args.out_dir)\n",
        "\n",
        "    if args.data_name == 'ISIC':\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)), transforms.ToTensor(),]\n",
        "        transform_test = transforms.Compose(tran_list)\n",
        "\n",
        "        ds = ISICDataset(args, args.data_dir, transform_test, mode = 'Test')\n",
        "        args.in_ch = 4\n",
        "    elif args.data_name == 'BRATS':\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)),]\n",
        "        transform_test = transforms.Compose(tran_list)\n",
        "\n",
        "        ds = BRATSDataset3D(args.data_dir,transform_test)\n",
        "        args.in_ch = 5\n",
        "    else:\n",
        "        tran_list = [transforms.Resize((args.image_size,args.image_size)), transforms.ToTensor()]\n",
        "        transform_test = transforms.Compose(tran_list)\n",
        "\n",
        "        ds = CustomDataset(args, args.data_dir, transform_test, mode = 'Test')\n",
        "        args.in_ch = 4\n",
        "\n",
        "    datal = th.utils.data.DataLoader(\n",
        "        ds,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True)\n",
        "    data = iter(datal)\n",
        "\n",
        "    logger.log(\"creating model and diffusion...\")\n",
        "\n",
        "    model, diffusion = create_model_and_diffusion(\n",
        "        **args_to_dict(args, model_and_diffusion_defaults().keys())\n",
        "    )\n",
        "    all_images = []\n",
        "\n",
        "\n",
        "    state_dict = dist_util.load_state_dict(args.model_path, map_location=\"cpu\")\n",
        "    from collections import OrderedDict\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        # name = k[7:] # remove `module.`\n",
        "        if 'module.' in k:\n",
        "            new_state_dict[k[7:]] = v\n",
        "            # load params\n",
        "        else:\n",
        "            new_state_dict = state_dict\n",
        "\n",
        "    model.load_state_dict(new_state_dict)\n",
        "\n",
        "    model.to(dist_util.dev())\n",
        "    if args.use_fp16:\n",
        "        model.convert_to_fp16()\n",
        "    model.eval()\n",
        "    for _ in range(len(data)):\n",
        "        b, m, path = next(data)  #should return an image from the dataloader \"data\"\n",
        "        c = th.randn_like(b[:, :1, ...])\n",
        "        img = th.cat((b, c), dim=1)     #add a noise channel$\n",
        "        if args.data_name == 'ISIC':\n",
        "            slice_ID=path[0].split(\"_\")[-1].split('.')[0]\n",
        "        elif args.data_name == 'BRATS':\n",
        "            # slice_ID=path[0].split(\"_\")[2] + \"_\" + path[0].split(\"_\")[4]\n",
        "            slice_ID=path[0].split(\"_\")[-3] + \"_\" + path[0].split(\"slice\")[-1].split('.nii')[0]\n",
        "\n",
        "        logger.log(\"sampling...\")\n",
        "\n",
        "        start = th.cuda.Event(enable_timing=True)\n",
        "        end = th.cuda.Event(enable_timing=True)\n",
        "        enslist = []\n",
        "\n",
        "        for i in range(args.num_ensemble):  #this is for the generation of an ensemble of 5 masks.\n",
        "            model_kwargs = {}\n",
        "            start.record()\n",
        "            sample_fn = (\n",
        "                diffusion.p_sample_loop_known if not args.use_ddim else diffusion.ddim_sample_loop_known\n",
        "            )\n",
        "            # pdb.set_trace() #imbedded debug !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "            # truncating model output after its internally calculated in dim 2 should fix the issue:\n",
        "            # https://github.com/SuperMedIntel/MedSegDiff/issues/201\n",
        "            # fixable by just editing gaussian_diffusion.py:346 to be permissive\n",
        "            sample, x_noisy, org, cal, cal_out = sample_fn( # broken\n",
        "                model,\n",
        "                (args.batch_size, 3, args.image_size, args.image_size), img,\n",
        "                step = args.diffusion_steps,\n",
        "                clip_denoised=args.clip_denoised,\n",
        "                model_kwargs=model_kwargs,\n",
        "            )\n",
        "\n",
        "            end.record()\n",
        "            th.cuda.synchronize()\n",
        "            print('time for 1 sample', start.elapsed_time(end))  #time measurement for the generation of 1 sample\n",
        "\n",
        "            co = th.tensor(cal_out)\n",
        "            if args.version == 'new':\n",
        "                enslist.append(sample[:,-1,:,:])\n",
        "            else:\n",
        "                enslist.append(co)\n",
        "\n",
        "            if args.debug:\n",
        "                # print('sample size is',sample.size())\n",
        "                # print('org size is',org.size())\n",
        "                # print('cal size is',cal.size())\n",
        "                if args.data_name == 'ISIC':\n",
        "                    # s = th.tensor(sample)[:,-1,:,:].unsqueeze(1).repeat(1, 3, 1, 1)\n",
        "                    o = th.tensor(org)[:,:-1,:,:]\n",
        "                    c = th.tensor(cal).repeat(1, 3, 1, 1)\n",
        "                    # co = co.repeat(1, 3, 1, 1)\n",
        "\n",
        "                    s = sample[:,-1,:,:]\n",
        "                    b,h,w = s.size()\n",
        "                    ss = s.clone()\n",
        "                    ss = ss.view(s.size(0), -1)\n",
        "                    ss -= ss.min(1, keepdim=True)[0]\n",
        "                    ss /= ss.max(1, keepdim=True)[0]\n",
        "                    ss = ss.view(b, h, w)\n",
        "                    ss = ss.unsqueeze(1).repeat(1, 3, 1, 1)\n",
        "\n",
        "                    tup = (ss,o,c)\n",
        "                elif args.data_name == 'BRATS':\n",
        "                    s = th.tensor(sample)[:,-1,:,:].unsqueeze(1)\n",
        "                    m = th.tensor(m.to(device = 'cuda:0'))[:,0,:,:].unsqueeze(1)\n",
        "                    o1 = th.tensor(org)[:,0,:,:].unsqueeze(1)\n",
        "                    o2 = th.tensor(org)[:,1,:,:].unsqueeze(1)\n",
        "                    o3 = th.tensor(org)[:,2,:,:].unsqueeze(1)\n",
        "                    o4 = th.tensor(org)[:,3,:,:].unsqueeze(1)\n",
        "                    c = th.tensor(cal)\n",
        "\n",
        "                    tup = (o1/o1.max(),o2/o2.max(),o3/o3.max(),o4/o4.max(),m,s,c,co)\n",
        "\n",
        "                compose = th.cat(tup,0)\n",
        "                vutils.save_image(compose, fp = os.path.join(args.out_dir, str(slice_ID)+'_output'+str(i)+\".jpg\"), nrow = 1, padding = 10)\n",
        "        ensres = staple(th.stack(enslist,dim=0)).squeeze(0)\n",
        "        vutils.save_image(ensres, fp = os.path.join(args.out_dir, str(slice_ID)+'_output_ens'+\".jpg\"), nrow = 1, padding = 10)"
      ],
      "metadata": {
        "id": "9wuvHH-DiCRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bugged section: x=x[:,-1:,...]  #loss is only calculated on the last channel, not on the input brain MR image\n",
        "# becomes:\n",
        "# x=x[:,-1:,...]\\n        if x.shape != model_output.shape:\\n            model_output = model_output[:,0,...]\n",
        "!sed 's/x=x[:,-1:,...]  #loss is only calculated on the last channel, not on the input brain MR image/x=x[:,-1:,...]\\n        if x.shape != model_output.shape:\\n            model_output = model_output[:,0,...]/' /content/scripts/guided_diffusion/gaussian_diffusion.py"
      ],
      "metadata": {
        "id": "T9vTCwaCekGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "IGQ1YgmHi3Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5lkM8JvL9fM"
      },
      "outputs": [],
      "source": [
        "!ls /kaggle/working/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udrPkrJqL9_k"
      },
      "outputs": [],
      "source": [
        "%cd /kaggle/working/out\n",
        "from IPython.display import FileLink\n",
        "FileLink('/kaggle/working/out/optsavedmodel000000.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_3tkd7lMAMR"
      },
      "outputs": [],
      "source": [
        "!tar -cf models.tar /kaggle/working/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLMGVTlMMBrp"
      },
      "outputs": [],
      "source": [
        "!ls /kaggle/working/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pHdtluDMC5y"
      },
      "outputs": [],
      "source": [
        "!tar czvf model_tar2.tar.gz /kaggle/working/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NgQslhBMElC"
      },
      "outputs": [],
      "source": [
        "!ls -alh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6h7nl_dMF3u"
      },
      "outputs": [],
      "source": [
        "!tar -tvf ./model_tar2.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f65s16gQguvW"
      },
      "outputs": [],
      "source": [
        "!nvidia_smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZDlerMDMQP3"
      },
      "outputs": [],
      "source": [
        "sample()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/"
      ],
      "metadata": {
        "id": "19YNeVJvfHUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhBf4IcFMTDn"
      },
      "outputs": [],
      "source": [
        "!ls /kaggle/working/out\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "display(Image.open('/kaggle/working/out/0010016_output_ens.jpg'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/ISIC_0010016_Segmentation.png'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_Data/ISIC_0010016.jpg'))\n",
        "\n",
        "display(Image.open('/kaggle/working/out/0010336_output_ens.jpg'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/ISIC_0010336_Segmentation.png'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_Data/ISIC_0010336.jpg'))\n",
        "\n",
        "display(Image.open('/kaggle/working/out/0010437_output_ens.jpg'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/ISIC_0010437_Segmentation.png'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_Data/ISIC_0010437.jpg'))\n",
        "\n",
        "display(Image.open('/kaggle/working/out/0010494_output_ens.jpg'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/ISIC_0010494_Segmentation.png'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_Data/ISIC_0010494.jpg'))\n",
        "\n",
        "display(Image.open('/kaggle/working/out/0010574_output_ens.jpg'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_GroundTruth/ISIC_0010574_Segmentation.png'))\n",
        "display(Image.open('/kaggle/working/isic/ISBI2016_ISIC_Part1_Test_Data/ISIC_0010574.jpg'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}